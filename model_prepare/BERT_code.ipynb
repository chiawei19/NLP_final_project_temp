{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import codecs\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./data/training/\"\n",
    "TRAIN_SUFFIX = \"-train.txt\"\n",
    "\n",
    "DEV_DIR = \"./data/development/\"\n",
    "DEV_SUFFIX = \"-dev.txt\"\n",
    "\n",
    "TEST_DIR = \"./data/test-gold/\"\n",
    "TEST_SUFFIX = \"-test-gold.txt\"\n",
    "\n",
    "YEAR_PREFIX = \"2018-\"\n",
    "FILE_PREFIX = \"EI-oc-En-\"\n",
    "\n",
    "EMOTIONS = [\"anger\", \"fear\", \"joy\", \"sadness\"] \n",
    "LABEL_EMOTIONS = {i: emo for i, emo in enumerate(EMOTIONS)}\n",
    "EMOTIONS_LABEL = {emo: i for i, emo in enumerate(EMOTIONS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/training/EI-oc-En-anger-train.txt True\n",
      "./data/training/EI-oc-En-fear-train.txt True\n",
      "./data/training/EI-oc-En-joy-train.txt True\n",
      "./data/training/EI-oc-En-sadness-train.txt True\n",
      "./data/development/2018-EI-oc-En-anger-dev.txt True\n",
      "./data/development/2018-EI-oc-En-fear-dev.txt True\n",
      "./data/development/2018-EI-oc-En-joy-dev.txt True\n",
      "./data/development/2018-EI-oc-En-sadness-dev.txt True\n",
      "./data/test-gold/2018-EI-oc-En-anger-test-gold.txt True\n",
      "./data/test-gold/2018-EI-oc-En-fear-test-gold.txt True\n",
      "./data/test-gold/2018-EI-oc-En-joy-test-gold.txt True\n",
      "./data/test-gold/2018-EI-oc-En-sadness-test-gold.txt True\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILES = []\n",
    "DEV_FILES = []\n",
    "TEST_FILES = []\n",
    "\n",
    "for emo in EMOTIONS: \n",
    "    TRAIN_FILES += [TRAIN_DIR + FILE_PREFIX + emo + TRAIN_SUFFIX]\n",
    "    DEV_FILES += [DEV_DIR + YEAR_PREFIX + FILE_PREFIX + emo + DEV_SUFFIX]\n",
    "    TEST_FILES += [TEST_DIR + YEAR_PREFIX + FILE_PREFIX + emo + TEST_SUFFIX]\n",
    "\n",
    "for file in TRAIN_FILES + DEV_FILES + TEST_FILES:\n",
    "    print(file, os.path.exists(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>2017-En-30404</td>\n",
       "      <td>@carysmithwriter @Maria_Savva @RealRockAndRoll...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1: low amount of joy can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2017-En-31434</td>\n",
       "      <td>@Somong_MGMT We need 2 bust up the elites in D...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0: no joy can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2017-En-21549</td>\n",
       "      <td>@BowkerMorgan awe thanks morgs!!! love u lots ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2017-En-10175</td>\n",
       "      <td>Forgot to eat dinner and now I'm furious with ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3: high amount of anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2017-En-22203</td>\n",
       "      <td>Angel got me nervous out here üò∑</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2017-En-30802</td>\n",
       "      <td>Wanted to get him a cake with sparkling candle...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0: no joy can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2017-En-21144</td>\n",
       "      <td>@FraserKeegan just had a steak pie supper</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>2017-En-11529</td>\n",
       "      <td>Now that the n word is normalized by the media...</td>\n",
       "      <td>anger</td>\n",
       "      <td>2: moderate amount of anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2017-En-21955</td>\n",
       "      <td>Huge congrats to my friends at @VoidMovie on t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>2017-En-21612</td>\n",
       "      <td>Skydive booked üòÅüòÅ #nervous üõ©</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  \\\n",
       "1384  2017-En-30404  @carysmithwriter @Maria_Savva @RealRockAndRoll...   \n",
       "760   2017-En-31434  @Somong_MGMT We need 2 bust up the elites in D...   \n",
       "2149  2017-En-21549  @BowkerMorgan awe thanks morgs!!! love u lots ...   \n",
       "509   2017-En-10175  Forgot to eat dinner and now I'm furious with ...   \n",
       "609   2017-En-22203                    Angel got me nervous out here üò∑   \n",
       "...             ...                                                ...   \n",
       "978   2017-En-30802  Wanted to get him a cake with sparkling candle...   \n",
       "1563  2017-En-21144         @FraserKeegan just had a steak pie supper    \n",
       "1653  2017-En-11529  Now that the n word is normalized by the media...   \n",
       "906   2017-En-21955  Huge congrats to my friends at @VoidMovie on t...   \n",
       "1031  2017-En-21612                       Skydive booked üòÅüòÅ #nervous üõ©   \n",
       "\n",
       "     Affect Dimension                              Intensity Class  \n",
       "1384              joy         1: low amount of joy can be inferred  \n",
       "760               joy                    0: no joy can be inferred  \n",
       "2149             fear                   0: no fear can be inferred  \n",
       "509             anger      3: high amount of anger can be inferred  \n",
       "609              fear   2: moderate amount of fear can be inferred  \n",
       "...               ...                                          ...  \n",
       "978               joy                    0: no joy can be inferred  \n",
       "1563             fear                   0: no fear can be inferred  \n",
       "1653            anger  2: moderate amount of anger can be inferred  \n",
       "906              fear                   0: no fear can be inferred  \n",
       "1031             fear   2: moderate amount of fear can be inferred  \n",
       "\n",
       "[7102 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA = pd.concat(pd.read_csv(f, sep='\\t') for f in TRAIN_FILES)\n",
    "TRAIN_DATA = sklearn.utils.shuffle(TRAIN_DATA)\n",
    "TRAIN_DATA        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>2017-En-30404</td>\n",
       "      <td>@carysmithwriter @Maria_Savva @RealRockAndRoll...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1: low amount of joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2017-En-31434</td>\n",
       "      <td>@Somong_MGMT We need 2 bust up the elites in D...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0: no joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2017-En-21549</td>\n",
       "      <td>@BowkerMorgan awe thanks morgs!!! love u lots ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2017-En-10175</td>\n",
       "      <td>Forgot to eat dinner and now I'm furious with ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3: high amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2017-En-22203</td>\n",
       "      <td>Angel got me nervous out here üò∑</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2017-En-30802</td>\n",
       "      <td>Wanted to get him a cake with sparkling candle...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0: no joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2017-En-21144</td>\n",
       "      <td>@FraserKeegan just had a steak pie supper</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>2017-En-11529</td>\n",
       "      <td>Now that the n word is normalized by the media...</td>\n",
       "      <td>anger</td>\n",
       "      <td>2: moderate amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2017-En-21955</td>\n",
       "      <td>Huge congrats to my friends at @VoidMovie on t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>2017-En-21612</td>\n",
       "      <td>Skydive booked üòÅüòÅ #nervous üõ©</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  \\\n",
       "1384  2017-En-30404  @carysmithwriter @Maria_Savva @RealRockAndRoll...   \n",
       "760   2017-En-31434  @Somong_MGMT We need 2 bust up the elites in D...   \n",
       "2149  2017-En-21549  @BowkerMorgan awe thanks morgs!!! love u lots ...   \n",
       "509   2017-En-10175  Forgot to eat dinner and now I'm furious with ...   \n",
       "609   2017-En-22203                    Angel got me nervous out here üò∑   \n",
       "...             ...                                                ...   \n",
       "978   2017-En-30802  Wanted to get him a cake with sparkling candle...   \n",
       "1563  2017-En-21144         @FraserKeegan just had a steak pie supper    \n",
       "1653  2017-En-11529  Now that the n word is normalized by the media...   \n",
       "906   2017-En-21955  Huge congrats to my friends at @VoidMovie on t...   \n",
       "1031  2017-En-21612                       Skydive booked üòÅüòÅ #nervous üõ©   \n",
       "\n",
       "     Affect Dimension                              Intensity Class Category  \\\n",
       "1384              joy         1: low amount of joy can be inferred      joy   \n",
       "760               joy                    0: no joy can be inferred      joy   \n",
       "2149             fear                   0: no fear can be inferred     fear   \n",
       "509             anger      3: high amount of anger can be inferred    anger   \n",
       "609              fear   2: moderate amount of fear can be inferred     fear   \n",
       "...               ...                                          ...      ...   \n",
       "978               joy                    0: no joy can be inferred      joy   \n",
       "1563             fear                   0: no fear can be inferred     fear   \n",
       "1653            anger  2: moderate amount of anger can be inferred    anger   \n",
       "906              fear                   0: no fear can be inferred     fear   \n",
       "1031             fear   2: moderate amount of fear can be inferred     fear   \n",
       "\n",
       "      Label  Intensity  \n",
       "1384      2          1  \n",
       "760       2          0  \n",
       "2149      1          0  \n",
       "509       0          3  \n",
       "609       1          2  \n",
       "...     ...        ...  \n",
       "978       2          0  \n",
       "1563      1          0  \n",
       "1653      0          2  \n",
       "906       1          0  \n",
       "1031      1          2  \n",
       "\n",
       "[7102 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[\"Category\"] = TRAIN_DATA[\"Affect Dimension\"]\n",
    "TRAIN_DATA[\"Label\"] = TRAIN_DATA[\"Affect Dimension\"].apply(lambda x: EMOTIONS_LABEL[x])\n",
    "TRAIN_DATA[\"Intensity\"] = TRAIN_DATA[\"Intensity Class\"].apply(lambda x: int(x[0]))\n",
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear       2252\n",
       "anger      1701\n",
       "joy        1616\n",
       "sadness    1533\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2018-En-03024</td>\n",
       "      <td>@AChubbyPanda *He would growl softly and licks...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2018-En-03352</td>\n",
       "      <td>Selling nudes pics and vids kik me to buy! Dir...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2018-En-01524</td>\n",
       "      <td>@NRO @Acosta @CNN @realDonaldTrump remember wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1: low amount of anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2018-En-00794</td>\n",
       "      <td>@620wtmj Seriously @620wtmj !? This is news to...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2: moderate amount of sadness can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018-En-01525</td>\n",
       "      <td>@BeautinaSuit No need to thank me.. I'm just t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2: moderate amount of joy can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2018-En-00688</td>\n",
       "      <td>@AwardsDaily Looks that way.  I don't want to ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1: low amount of anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2018-En-02646</td>\n",
       "      <td>Beware the wrath of an angry, frustrated, #agi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2018-En-04274</td>\n",
       "      <td>@Cmdr_Hadfield CNN's Wolf Blitzer calls you an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2: moderate amount of sadness can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2018-En-01143</td>\n",
       "      <td>My best friends driving for the first time wit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2018-En-03362</td>\n",
       "      <td>Wrapped In This Burrito, Gotta Sweat This All ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0: no sadness can be inferred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                              Tweet  \\\n",
       "249  2018-En-03024  @AChubbyPanda *He would growl softly and licks...   \n",
       "334  2018-En-03352  Selling nudes pics and vids kik me to buy! Dir...   \n",
       "277  2018-En-01524  @NRO @Acosta @CNN @realDonaldTrump remember wh...   \n",
       "133  2018-En-00794  @620wtmj Seriously @620wtmj !? This is news to...   \n",
       "110  2018-En-01525  @BeautinaSuit No need to thank me.. I'm just t...   \n",
       "..             ...                                                ...   \n",
       "108  2018-En-00688  @AwardsDaily Looks that way.  I don't want to ...   \n",
       "368  2018-En-02646  Beware the wrath of an angry, frustrated, #agi...   \n",
       "253  2018-En-04274  @Cmdr_Hadfield CNN's Wolf Blitzer calls you an...   \n",
       "347  2018-En-01143  My best friends driving for the first time wit...   \n",
       "319  2018-En-03362  Wrapped In This Burrito, Gotta Sweat This All ...   \n",
       "\n",
       "    Affect Dimension                                Intensity Class  \n",
       "249            anger                    0: no anger can be inferred  \n",
       "334            anger                    0: no anger can be inferred  \n",
       "277            anger         1: low amount of anger can be inferred  \n",
       "133          sadness  2: moderate amount of sadness can be inferred  \n",
       "110              joy      2: moderate amount of joy can be inferred  \n",
       "..               ...                                            ...  \n",
       "108            anger         1: low amount of anger can be inferred  \n",
       "368             fear     2: moderate amount of fear can be inferred  \n",
       "253          sadness  2: moderate amount of sadness can be inferred  \n",
       "347            anger                    0: no anger can be inferred  \n",
       "319          sadness                  0: no sadness can be inferred  \n",
       "\n",
       "[1464 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_DATA = pd.concat(pd.read_csv(f, sep='\\t') for f in DEV_FILES)\n",
    "DEV_DATA = sklearn.utils.shuffle(DEV_DATA)\n",
    "DEV_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2018-En-03024</td>\n",
       "      <td>@AChubbyPanda *He would growl softly and licks...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2018-En-03352</td>\n",
       "      <td>Selling nudes pics and vids kik me to buy! Dir...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2018-En-01524</td>\n",
       "      <td>@NRO @Acosta @CNN @realDonaldTrump remember wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1: low amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2018-En-00794</td>\n",
       "      <td>@620wtmj Seriously @620wtmj !? This is news to...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2: moderate amount of sadness can be inferred</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018-En-01525</td>\n",
       "      <td>@BeautinaSuit No need to thank me.. I'm just t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2: moderate amount of joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2018-En-00688</td>\n",
       "      <td>@AwardsDaily Looks that way.  I don't want to ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1: low amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2018-En-02646</td>\n",
       "      <td>Beware the wrath of an angry, frustrated, #agi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2018-En-04274</td>\n",
       "      <td>@Cmdr_Hadfield CNN's Wolf Blitzer calls you an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2: moderate amount of sadness can be inferred</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2018-En-01143</td>\n",
       "      <td>My best friends driving for the first time wit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2018-En-03362</td>\n",
       "      <td>Wrapped In This Burrito, Gotta Sweat This All ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0: no sadness can be inferred</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                              Tweet  \\\n",
       "249  2018-En-03024  @AChubbyPanda *He would growl softly and licks...   \n",
       "334  2018-En-03352  Selling nudes pics and vids kik me to buy! Dir...   \n",
       "277  2018-En-01524  @NRO @Acosta @CNN @realDonaldTrump remember wh...   \n",
       "133  2018-En-00794  @620wtmj Seriously @620wtmj !? This is news to...   \n",
       "110  2018-En-01525  @BeautinaSuit No need to thank me.. I'm just t...   \n",
       "..             ...                                                ...   \n",
       "108  2018-En-00688  @AwardsDaily Looks that way.  I don't want to ...   \n",
       "368  2018-En-02646  Beware the wrath of an angry, frustrated, #agi...   \n",
       "253  2018-En-04274  @Cmdr_Hadfield CNN's Wolf Blitzer calls you an...   \n",
       "347  2018-En-01143  My best friends driving for the first time wit...   \n",
       "319  2018-En-03362  Wrapped In This Burrito, Gotta Sweat This All ...   \n",
       "\n",
       "    Affect Dimension                                Intensity Class Category  \\\n",
       "249            anger                    0: no anger can be inferred    anger   \n",
       "334            anger                    0: no anger can be inferred    anger   \n",
       "277            anger         1: low amount of anger can be inferred    anger   \n",
       "133          sadness  2: moderate amount of sadness can be inferred  sadness   \n",
       "110              joy      2: moderate amount of joy can be inferred      joy   \n",
       "..               ...                                            ...      ...   \n",
       "108            anger         1: low amount of anger can be inferred    anger   \n",
       "368             fear     2: moderate amount of fear can be inferred     fear   \n",
       "253          sadness  2: moderate amount of sadness can be inferred  sadness   \n",
       "347            anger                    0: no anger can be inferred    anger   \n",
       "319          sadness                  0: no sadness can be inferred  sadness   \n",
       "\n",
       "     Label  Intensity  \n",
       "249      0          0  \n",
       "334      0          0  \n",
       "277      0          1  \n",
       "133      3          2  \n",
       "110      2          2  \n",
       "..     ...        ...  \n",
       "108      0          1  \n",
       "368      1          2  \n",
       "253      3          2  \n",
       "347      0          0  \n",
       "319      3          0  \n",
       "\n",
       "[1464 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_DATA[\"Category\"] = DEV_DATA[\"Affect Dimension\"]\n",
    "DEV_DATA[\"Label\"] = DEV_DATA[\"Affect Dimension\"].apply(lambda x: EMOTIONS_LABEL[x])\n",
    "DEV_DATA[\"Intensity\"] = DEV_DATA[\"Intensity Class\"].apply(lambda x: int(x[0]))\n",
    "DEV_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness    397\n",
       "fear       389\n",
       "anger      388\n",
       "joy        290\n",
       "Name: Affect Dimension, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_DATA[\"Affect Dimension\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Pre-Processing\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# For visualizing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_emoji(text):\n",
    "    output = []\n",
    "    for t in emoji.demojize(text).split():\n",
    "        output.extend(t.split(\"_\"))\n",
    "    return ' '.join(output)\n",
    "\n",
    "def decode_HTML(text):\n",
    "    return BeautifulSoup(text, 'lxml').get_text()\n",
    "\n",
    "def remove_mention(text):\n",
    "    return re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    \n",
    "def remove_URL(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "def to_lowercase(text):\n",
    "    return ' '.join([w.lower() for w in text.split()])\n",
    " \n",
    "def lemmatize_stemming(text):\n",
    "    return ' '.join([stemmer.stem(lemmatizer.lemmatize(w, pos='v'))\n",
    "                     for w in text.split()])\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([w for w in text.split() if w not in stop_words ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    text = decode_emoji(text)\n",
    "    text = decode_HTML(text)\n",
    "    text = remove_mention(text)\n",
    "    text = remove_URL(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lowercase(text)\n",
    "#     text = lemmatize_stemming(text)\n",
    "    text = remove_stop_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: @carysmithwriter @Maria_Savva @RealRockAndRoll We're the least known band in the World, but so glad you asked #muchlove \n",
      "AFTER : savva least known band world glad asked muchlove\n",
      "\n",
      "BEFORE: @Somong_MGMT We need 2 bust up the elites in DC, we need jobs 4 all, we need to clean up the blithe in inner Cities, rebuild housing...cont2\n",
      "AFTER : mgmt need 2 bust elites dc need jobs 4 need clean blithe inner cities rebuild housing cont2\n",
      "\n",
      "BEFORE: @BowkerMorgan awe thanks morgs!!! love u lots girly ‚ù§Ô∏èüòä‚ù§Ô∏è\n",
      "AFTER : awe thanks morgs love u lots girly red heart selector smiling face smiling eyes red heart selector\n",
      "\n",
      "BEFORE: Forgot to eat dinner and now I'm furious with everything and everyone\n",
      "AFTER : forgot eat dinner furious everything everyone\n",
      "\n",
      "BEFORE: Angel got me nervous out here üò∑\n",
      "AFTER : angel got nervous face medical mask\n",
      "\n",
      "BEFORE: 3 Styles to Love now at Zales!  Three sparkling styles to love! Stop by and shop in store today.\n",
      "AFTER : 3 styles love zales three sparkling styles love stop shop store today\n",
      "\n",
      "BEFORE: can't believe Mint fest is two days away and i hate my outfit üò©üò©üôà \n",
      "AFTER : believe mint fest two days away hate outfit weary face weary face see evil monkey\n",
      "\n",
      "BEFORE: @David_Stepp Any other election, fine vote 3rd party as useless as it is but not this one. I hesitate to say it'd be selfish but...\n",
      "AFTER : stepp election fine vote 3rd party useless one hesitate say selfish\n",
      "\n",
      "BEFORE: My heartbeat is forever stumbling on memories of things past. #longing #loss #shape #form #sadness\n",
      "AFTER : heartbeat forever stumbling memories things past longing loss shape form sadness\n",
      "\n",
      "BEFORE: Watching Paranormal Activity: The Ghost Dimension. I'm not sure how I feel about it yet. #horror\n",
      "AFTER : watching paranormal activity ghost dimension sure feel yet horror\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in TRAIN_DATA[\"Tweet\"][:10]:\n",
    "    print(\"BEFORE:\", t)\n",
    "    print(\"AFTER :\", pre_process(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>2017-En-30404</td>\n",
       "      <td>@carysmithwriter @Maria_Savva @RealRockAndRoll...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1: low amount of joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>savva least known band world glad asked muchlove</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2017-En-31434</td>\n",
       "      <td>@Somong_MGMT We need 2 bust up the elites in D...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0: no joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>mgmt need 2 bust elites dc need jobs 4 need cl...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2017-En-21549</td>\n",
       "      <td>@BowkerMorgan awe thanks morgs!!! love u lots ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0: no fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>awe thanks morgs love u lots girly red heart s...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2017-En-10175</td>\n",
       "      <td>Forgot to eat dinner and now I'm furious with ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3: high amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>forgot eat dinner furious everything everyone</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2017-En-22203</td>\n",
       "      <td>Angel got me nervous out here üò∑</td>\n",
       "      <td>fear</td>\n",
       "      <td>2: moderate amount of fear can be inferred</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>angel got nervous face medical mask</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  \\\n",
       "1384  2017-En-30404  @carysmithwriter @Maria_Savva @RealRockAndRoll...   \n",
       "760   2017-En-31434  @Somong_MGMT We need 2 bust up the elites in D...   \n",
       "2149  2017-En-21549  @BowkerMorgan awe thanks morgs!!! love u lots ...   \n",
       "509   2017-En-10175  Forgot to eat dinner and now I'm furious with ...   \n",
       "609   2017-En-22203                    Angel got me nervous out here üò∑   \n",
       "\n",
       "     Affect Dimension                             Intensity Class Category  \\\n",
       "1384              joy        1: low amount of joy can be inferred      joy   \n",
       "760               joy                   0: no joy can be inferred      joy   \n",
       "2149             fear                  0: no fear can be inferred     fear   \n",
       "509             anger     3: high amount of anger can be inferred    anger   \n",
       "609              fear  2: moderate amount of fear can be inferred     fear   \n",
       "\n",
       "      Label  Intensity                                               Text  \\\n",
       "1384      2          1   savva least known band world glad asked muchlove   \n",
       "760       2          0  mgmt need 2 bust elites dc need jobs 4 need cl...   \n",
       "2149      1          0  awe thanks morgs love u lots girly red heart s...   \n",
       "509       0          3      forgot eat dinner furious everything everyone   \n",
       "609       1          2                angel got nervous face medical mask   \n",
       "\n",
       "      Text_len  \n",
       "1384         8  \n",
       "760         17  \n",
       "2149        17  \n",
       "509          6  \n",
       "609          6  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data cleaning\n",
    "TRAIN_DATA[\"Text\"] = TRAIN_DATA[\"Tweet\"].apply(lambda s: pre_process(s))\n",
    "TRAIN_DATA[\"Text_len\"] = TRAIN_DATA[\"Text\"].apply(lambda s: len(s.split()))\n",
    "TRAIN_DATA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2018-En-03024</td>\n",
       "      <td>@AChubbyPanda *He would growl softly and licks...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would growl softly licks lips need prove think...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2018-En-03352</td>\n",
       "      <td>Selling nudes pics and vids kik me to buy! Dir...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0: no anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selling nudes pics vids kik buy dirty becca69 ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2018-En-01524</td>\n",
       "      <td>@NRO @Acosta @CNN @realDonaldTrump remember wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1: low amount of anger can be inferred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>remember nro gave cnn grief relentless hc emai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2018-En-00794</td>\n",
       "      <td>@620wtmj Seriously @620wtmj !? This is news to...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2: moderate amount of sadness can be inferred</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>seriously news sad n nwhy focus important issues</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018-En-01525</td>\n",
       "      <td>@BeautinaSuit No need to thank me.. I'm just t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2: moderate amount of joy can be inferred</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>need thank telling like smiling face smiling e...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                              Tweet  \\\n",
       "249  2018-En-03024  @AChubbyPanda *He would growl softly and licks...   \n",
       "334  2018-En-03352  Selling nudes pics and vids kik me to buy! Dir...   \n",
       "277  2018-En-01524  @NRO @Acosta @CNN @realDonaldTrump remember wh...   \n",
       "133  2018-En-00794  @620wtmj Seriously @620wtmj !? This is news to...   \n",
       "110  2018-En-01525  @BeautinaSuit No need to thank me.. I'm just t...   \n",
       "\n",
       "    Affect Dimension                                Intensity Class Category  \\\n",
       "249            anger                    0: no anger can be inferred    anger   \n",
       "334            anger                    0: no anger can be inferred    anger   \n",
       "277            anger         1: low amount of anger can be inferred    anger   \n",
       "133          sadness  2: moderate amount of sadness can be inferred  sadness   \n",
       "110              joy      2: moderate amount of joy can be inferred      joy   \n",
       "\n",
       "     Label  Intensity                                               Text  \\\n",
       "249      0          0  would growl softly licks lips need prove think...   \n",
       "334      0          0  selling nudes pics vids kik buy dirty becca69 ...   \n",
       "277      0          1  remember nro gave cnn grief relentless hc emai...   \n",
       "133      3          2   seriously news sad n nwhy focus important issues   \n",
       "110      2          2  need thank telling like smiling face smiling e...   \n",
       "\n",
       "     Text_len  \n",
       "249        13  \n",
       "334        20  \n",
       "277        10  \n",
       "133         8  \n",
       "110        15  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dev data cleaning\n",
    "DEV_DATA[\"Text\"] = DEV_DATA[\"Tweet\"].apply(lambda s: pre_process(s))\n",
    "DEV_DATA[\"Text_len\"] = DEV_DATA[\"Text\"].apply(lambda s: len(s.split()))\n",
    "DEV_DATA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7102.000000\n",
      "mean        9.406787\n",
      "std         4.368464\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%         9.000000\n",
      "75%        12.000000\n",
      "max        79.000000\n",
      "Name: Text_len, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(TRAIN_DATA[\"Text_len\"].describe())\n",
    "\n",
    "plt.hist(TRAIN_DATA[\"Text_len\"], color='blue', edgecolor='black')\n",
    "plt.title('Histogram of cleaned tweet length')\n",
    "plt.xlabel('length (word)')\n",
    "plt.ylabel('tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: @priny_baby happppy happppyyyyyy happppppyyyyy haaapppyyyy birthday best friend!! Love you lots üíñüíñüíñüíñüíñüíñüíñüéâüéä #chapter22 #bdaygirl  #love\n",
      "AFTER : baby happppy happppyyyyyy happppppyyyyy haaapppyyyy birthday best friend love lots sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart party popper confetti ball chapter22 bdaygirl love\n",
      "\n",
      "BEFORE: Fast and furious 6 this Monday 10 pm on mbc 2 üòçüòçüòçüòçüòçüòçüòç\n",
      "AFTER : fast furious 6 monday 10 pm mbc 2 smiling face heart eyes smiling face heart eyes smiling face heart eyes smiling face heart eyes smiling face heart eyes smiling face heart eyes smiling face heart eyes\n",
      "\n",
      "BEFORE: i will never watch greys anatomy ever ever ever ever ever again if Shonda Rimes takes away another OG character‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è #fuming\n",
      "AFTER : never watch greys anatomy ever ever ever ever ever shonda rimes takes away another og character frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector fuming\n",
      "\n",
      "BEFORE: @priny_baby happppy happppyyyyyy happppppyyyyy haaapppyyyy birthday best friend!! Love you lots üíñüíñüíñüíñüíñüíñüíñüéâüéä #chapter22 #bdaygirl #happy #love\n",
      "AFTER : baby happppy happppyyyyyy happppppyyyyy haaapppyyyy birthday best friend love lots sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart sparkling heart party popper confetti ball chapter22 bdaygirl happy love\n",
      "\n",
      "BEFORE: semores: let's get this. #mirth #SAW #keepthetradition üíúüíõ‚öõüèµüçáüçãüåºüê§üê•üëöüòàüòàüëæüßÄ\n",
      "AFTER : semores let get mirth saw keepthetradition purple heart yellow heart atom symbol rosette grapes lemon blossom baby chick front facing baby chick woman clothes smiling face horns smiling face horns alien monster cheese wedge\n",
      "\n",
      "BEFORE: Nahhhhhh @konanplaydirty snap story has got me bussing up üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ\n",
      "AFTER : nahhhhhh snap story got bussing face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy face tears joy\n",
      "\n",
      "BEFORE: Good morning, Trondheim! #optimism #productivity ‚õÖÔ∏è‚ù§Ô∏èüá≥üá¥üè¢üíªüñ•üèãüèªüí™üèºüì∫üçø\n",
      "AFTER : good morning trondheim optimism productivity sun behind cloud red heart selector norway office building laptop computer desktop computer person lifting weights light skin tone flexed biceps medium light skin tone television popcorn\n",
      "\n",
      "BEFORE: i will never watch greys anatomy ever ever ever ever ever again if Shonda Rimes takes away another OG character‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è \n",
      "AFTER : never watch greys anatomy ever ever ever ever ever shonda rimes takes away another og character frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector frowning face selector\n",
      "\n",
      "BEFORE: Trying to think positive, and not let this situation discourage me ‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®‚ú®\n",
      "AFTER : trying think positive let situation discourage sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles sparkles\n",
      "\n",
      "BEFORE: Think I really broke young bull hurt üòÇüòÇüò≠üò≠ u can tell by how bitter and mad he is üòäüòäüò©üò©\n",
      "AFTER : think really broke young bull hurt face tears joy face tears joy loudly crying face loudly crying face u tell bitter mad smiling face smiling eyes smiling face smiling eyes weary face weary face\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, t in TRAIN_DATA.iterrows():\n",
    "    if t[\"Text_len\"] > 30:\n",
    "        print(\"BEFORE:\", t[\"Tweet\"])\n",
    "        print(\"AFTER :\", t[\"Text\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size:  12909\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(word for text in TRAIN_DATA['Text'] for word in text.split())\n",
    "words_list = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n",
    "word_index = {word[0]: i+1 for i, word in enumerate(words_list)}\n",
    "print(\"dictionary size: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_text(words):\n",
    "    if len(words) >= max_seq_len:\n",
    "        return words[: max_seq_len]\n",
    "    else:\n",
    "        pad_len = max_seq_len - len(words)\n",
    "        padding = np.zeros(pad_len)\n",
    "        return np.concatenate((padding, words), axis=0)\n",
    "\n",
    "def words_to_seq(words):\n",
    "    return np.array([word_index.get(word, 0) for word in words])\n",
    "\n",
    "def prep(data):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for X, y in zip(data[\"Tweet\"], data[\"Label\"]):\n",
    "        words = pre_process(X).split()\n",
    "        if len(words) > 0:\n",
    "            X_data.append(pre_process(X))\n",
    "            y_data.append(y)\n",
    "            \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prep(TRAIN_DATA)\n",
    "X_dev, y_dev = prep(DEV_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict accuracy\n",
    "def acc(pred, label):\n",
    "    pred = torch.argmax(pred, 1)\n",
    "    return torch.sum(pred == label).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the accuracy and loss\n",
    "def plot_acc_loss(tr_acc, vl_acc, tr_loss, vl_loss):\n",
    "    fig = plt.figure(figsize = (20, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "    plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epoch_tr_loss, label='Train loss')\n",
    "    plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3208a35af8475a9db2503de06d2007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7c7829c8e442fbbdc5d7bb147db6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b89f33ba994bcfbb35dd1e8389a5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46870681f177406cacbf4cea5da25cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text = tokenizer.tokenize(some_text)\n",
    "# tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(text):\n",
    "    tokens_text = tokenizer.batch_encode_plus(\n",
    "        text.tolist(),\n",
    "        max_length = 25,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    seq = torch.tensor(tokens_text['input_ids'])\n",
    "    mask = torch.tensor(tokens_text['attention_mask'])\n",
    "    return seq, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "\n",
    "        self.relu =  nn.ReLU()       \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        print(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "model = BERT_Arch(bert)\n",
    "lr = 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "#     for step, batch in enumerate(train_dataloader):   \n",
    "#         sent_id, mask, labels = batch\n",
    "        \n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "\n",
    "        inputs, masks= [], []\n",
    "        for t in X_train[start: start+batch_size]:\n",
    "            s, m = tokenizing(t)\n",
    "            inputs.append(s)\n",
    "            masks.append(m)\n",
    "            labels.append()\n",
    "        labels = torch.Tensor(y_train[start: start+batch_size]).long()\n",
    "\n",
    "        print(inputs)\n",
    "        print(masks)\n",
    "        print(labels)\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(inputs, masks)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c5138ddf6b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Epoch {:} / {:}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bi-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=64, no_layers=2, dropout=0.2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.no_layers = no_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.dimension = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim,\n",
    "                            hidden_size=self.dimension,\n",
    "                            num_layers=self.no_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(2*self.hidden_dim, 4)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        text_len = np.array([len(t) for t in text]) \n",
    "        \n",
    "        padded_input = pad_sequence(text, batch_first=True)\n",
    "        embbed_input = self.embedding(padded_input)\n",
    "        packed_input = pack_padded_sequence(embbed_input, text_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, output_len = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        \n",
    "        out_forward = torch.cat([torch.mean(t[:l, :self.dimension], 0, keepdim=True) for (t, l) in zip(output, output_len)])\n",
    "        out_reverse = torch.cat([torch.mean(t[-l:, self.dimension:], 0, keepdim=True) for (t, l) in zip(output, output_len)])             \n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LSTM(\n",
      "  (embedding): Embedding(12910, 300)\n",
      "  (lstm): LSTM(300, 32, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "no_layers = 3\n",
    "vocab_size = nb_words\n",
    "hidden_dim = 32\n",
    "dropout = 0.1\n",
    "output_dim = 4\n",
    "\n",
    "model = LSTM(hidden_dim, no_layers, dropout)\n",
    "print(25*'==')\n",
    "print(model)\n",
    "print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 1.368250835273001 val_loss : 1.335102335611979\n",
      "train_accuracy : 32.44156575612504 val_accuracy : 36.36363636363637\n",
      "Validation loss decreased (inf --> 1.335102).  Saving model ...\n",
      "==================================================\n",
      "Epoch 2\n",
      "train_loss : 1.2525435272190306 val_loss : 1.2927789131800334\n",
      "train_accuracy : 46.05744860602647 val_accuracy : 36.91045796308954\n",
      "Validation loss decreased (1.335102 --> 1.292779).  Saving model ...\n",
      "==================================================\n",
      "Epoch 3\n",
      "train_loss : 1.1898780663808186 val_loss : 1.2820415496826172\n",
      "train_accuracy : 48.606026471416506 val_accuracy : 38.961038961038966\n",
      "Validation loss decreased (1.292779 --> 1.282042).  Saving model ...\n",
      "==================================================\n",
      "Epoch 4\n",
      "train_loss : 1.1455140842331781 val_loss : 1.2743817249933878\n",
      "train_accuracy : 52.661222190932136 val_accuracy : 39.50786056049214\n",
      "Validation loss decreased (1.282042 --> 1.274382).  Saving model ...\n",
      "==================================================\n",
      "Epoch 5\n",
      "train_loss : 1.0990502155489392 val_loss : 1.2705219268798829\n",
      "train_accuracy : 60.47592227541537 val_accuracy : 43.0622009569378\n",
      "Validation loss decreased (1.274382 --> 1.270522).  Saving model ...\n",
      "==================================================\n",
      "Epoch 6\n",
      "train_loss : 1.0608706225951512 val_loss : 1.277501686414083\n",
      "train_accuracy : 68.82568290622359 val_accuracy : 44.83937115516063\n",
      "==================================================\n",
      "Epoch 7\n",
      "train_loss : 1.0266573677460353 val_loss : 1.2689125935236614\n",
      "train_accuracy : 74.54238242748522 val_accuracy : 46.75324675324675\n",
      "Validation loss decreased (1.270522 --> 1.268913).  Saving model ...\n",
      "==================================================\n",
      "Epoch 8\n",
      "train_loss : 1.0003245746095974 val_loss : 1.2644577264785766\n",
      "train_accuracy : 77.20360461841734 val_accuracy : 47.09501025290499\n",
      "Validation loss decreased (1.268913 --> 1.264458).  Saving model ...\n",
      "==================================================\n",
      "Epoch 9\n",
      "train_loss : 0.9694373028145896 val_loss : 1.2603214263916016\n",
      "train_accuracy : 79.63953815826528 val_accuracy : 46.8215994531784\n",
      "Validation loss decreased (1.264458 --> 1.260321).  Saving model ...\n",
      "==================================================\n",
      "Epoch 10\n",
      "train_loss : 0.9463706736763319 val_loss : 1.2889730056126913\n",
      "train_accuracy : 80.69557871022248 val_accuracy : 44.087491455912506\n",
      "==================================================\n",
      "Epoch 11\n",
      "train_loss : 0.9397261581487126 val_loss : 1.2524012406667073\n",
      "train_accuracy : 81.14615601239088 val_accuracy : 47.71018455228982\n",
      "Validation loss decreased (1.260321 --> 1.252401).  Saving model ...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "clip = 5\n",
    "epochs = 30 \n",
    "batch_size = 100\n",
    "\n",
    "lr=0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "\n",
    "        inputs = [torch.from_numpy(t) for t in X_train[start: start+batch_size]]\n",
    "        labels = torch.Tensor(y_train[start: start+batch_size]).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_acc += acc(output, labels)\n",
    "\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        val_acc = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        for start in range(0, len(X_dev), batch_size): \n",
    "            v_inputs = [torch.from_numpy(t) for t in X_dev[start: start+batch_size]]\n",
    "            v_labels = torch.Tensor(y_dev[start: start+batch_size]).long()\n",
    "      \n",
    "            output = model(v_inputs)\n",
    "            val_loss = criterion(output, v_labels)\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            accuracy = acc(output, v_labels)\n",
    "            val_acc += accuracy\n",
    "        \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(X_train)\n",
    "    epoch_val_acc = val_acc/len(X_dev)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "#         torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')\n",
    "\n",
    "plot_acc_loss(epoch_tr_acc, epoch_vl_acc, epoch_tr_loss, epoch_vl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with fastText embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(tweet.split()) for tweet in TRAIN_DATA[\"Tweet\"]], color = 'blue', edgecolor = 'black')\n",
    "plt.title('Histogram of tweet length')\n",
    "plt.xlabel('length (word)')\n",
    "plt.ylabel('tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "WORD_DIM = 100\n",
    "\n",
    "def pad_text(words):\n",
    "    if len(words) >= MAX_LEN:\n",
    "        return words[: MAX_LEN]\n",
    "    else:\n",
    "        pad_len = MAX_LEN - len(words)\n",
    "#         padding = np.zeros((pad_len, WORD_DIM))\n",
    "        padding = np.zeros(pad_len)\n",
    "        return np.concatenate((words, padding), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_vec(words):\n",
    "    return np.array([fast_model.get_word_vector(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = set()\n",
    "for tweet in TRAIN_DATA[\"Tweet\"]:\n",
    "    words = pre_process(tweet).split()\n",
    "    for word in words:\n",
    "        vocabs.add(word)\n",
    "vocabs = list(sorted(vocabs))\n",
    "voc_to_id = {v: i+1 for i, v in enumerate(vocabs)}\n",
    "\n",
    "def words_to_id(words):\n",
    "    return np.array([voc_to_id.get(word, 0) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(data):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for X, y in zip(data[\"Tweet\"], data[\"Label\"]):\n",
    "        words = pre_process(X).split()\n",
    "        if len(words) > 0:\n",
    "#             X_data.append(pad_text(words_to_vec(words)))\n",
    "            X_data.append(pad_text(words_to_id((words))))\n",
    "            y_data.append(y)\n",
    "            \n",
    "    return np.array(X_data).astype(np.int_), np.array(y_data).astype(np.int_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prep(TRAIN_DATA)\n",
    "X_dev, y_dev = prep(DEV_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7102, 50)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0]), type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5):\n",
    "        super(SentimentRNN,self).__init__()\n",
    " \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding =nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "          \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 1000]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "              \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0, c0)\n",
    "        return hidden\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(13201, 300)\n",
      "  (lstm): LSTM(50, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocabs) + 1 #extra 1 for padding\n",
    "embedding_dim = 50\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 50, got 300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-be76806a181d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-282-1c822b25ae1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: B x S x Feature   since batch = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print(embeds.shape)  #[50, 500, 1000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    178\u001b[0m             raise RuntimeError(\n\u001b[1;32m    179\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 180\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 50, got 300"
     ]
    }
   ],
   "source": [
    "clip = 5\n",
    "epochs = 5 \n",
    "valid_loss_min = np.Inf\n",
    "# train for some number of epochs\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        print(len(train_losses) + 1, end=' ')\n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs,h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output, labels)\n",
    "        train_acc += accuracy\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    " \n",
    "    \n",
    "        \n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output,labels)\n",
    "            val_acc += accuracy\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_loader,\n",
    "          valid_loader = valid_loader,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_loader) // 2,\n",
    "#           file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:           \n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            output = model(titletext, titletext_len)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                  for v_inputs, v_labels in valid_loader:\n",
    "                      v_labels = v_labels.to(device)\n",
    "                      v_output = v_model(titletext, titletext_len)\n",
    "\n",
    "                      loss = criterion(output, labels)\n",
    "                      valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "#                 # checkpoint\n",
    "#                 if best_valid_loss > average_valid_loss:\n",
    "#                     best_valid_loss = average_valid_loss\n",
    "#                     save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "#                     save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "#     save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = LSTM().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
